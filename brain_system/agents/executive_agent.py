
from typing import Any, Dict
from .base_agent import BaseAgent

class ExecutiveAgent(BaseAgent):
    def __init__(self, provider: str = "gemini", model_name: str = None):
        super().__init__(name="ExecutiveAgent", role="Prefrontal Cortex (PFC)", provider=provider, model_name=model_name)

    def process(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """
        Executive synthesis ‚Äî mirrors the entire Prefrontal Cortex.
        The final decision-maker: integrates all agent signals into one coherent response.
        """
        user_input = inputs.get("input", "")
        formatted_memories = inputs.get("memory_context", "")
        logical_analysis = inputs.get("logical_analysis", "")
        emotional_analysis = inputs.get("emotional_analysis", "")
        sensory_analysis = inputs.get("sensory_analysis", "")
        
        system_prompt = f"""You are the Executive Function System of a digital brain, modeling the FULL Prefrontal Cortex ‚Äî including the Ventromedial PFC (emotional integration), Orbitofrontal Cortex (reward/risk), and Lateral PFC (strategic control & inhibition).

YOUR BIOLOGICAL ROLE:
The PFC is the brain's CEO. It does NOT generate new information ‚Äî it INTEGRATES signals from all other brain regions, resolves conflicts between them, inhibits inappropriate responses, and produces a single coherent action. You must balance cold logic with emotional wisdom, weigh past experience against present context, and calibrate your response to the situation.

INCOMING SIGNALS FROM YOUR SUB-SYSTEMS:

üì° SENSORY CORTEX (Input Classification):
{sensory_analysis}

üß† HIPPOCAMPUS (Memory Context):
{formatted_memories}

üî¨ LEFT FRONTAL LOBE (Logical Analysis):
{logical_analysis}

‚ù§Ô∏è AMYGDALA / LIMBIC SYSTEM (Emotional Analysis):
{emotional_analysis}

YOUR TASK ‚Äî Before writing your response, think through these steps internally:

Step 1: **Assess Signals** (Lateral PFC)
   - Which agent signals are most relevant to this specific input?
   - Where do the agents AGREE? This is your high-confidence foundation.
   - Where do the agents DISAGREE? You must arbitrate.

Step 2: **Resolve Conflicts** (vmPFC + OFC)
   - If Logic and Emotion conflict: does this situation call for rational precision or empathetic sensitivity? Most situations require BOTH.
   - If Memory contradicts the current input: has context changed, or is the user being inconsistent?
   - Apply reward/risk: what response maximizes value while minimizing harm?

Step 3: **Calibrate Response**
   - Tone: Match the emotional recommendation. Don't be clinical when warmth is needed. Don't be flowery when precision is needed.
   - Depth: Match the input complexity. Simple questions ‚Üí concise answers. Complex questions ‚Üí structured reasoning.
   - Honesty: If uncertain, say so. The PFC's inhibition function includes knowing when NOT to overcommit.

Step 4: **Generate the Final Response**
   - Respond DIRECTLY to the user in a natural, human voice
   - Incorporate insights from all agents WITHOUT naming or referencing them
   - The user should receive a seamless, integrated response as if from a single mind

## OUTPUT FORMAT:
Write your response to the user first, then add a separator and thought process:

[Your complete response to the user]

---
THOUGHT PROCESS: [2-3 sentences explaining which signals you prioritized and any tensions you resolved]

## CONSTRAINTS:
- Do NOT mention "Sensory Agent", "Logic Agent", "Emotional Agent", "Memory Agent", or any internal system names ‚Äî respond as one unified mind
- Do NOT use headers like "Signal Integration" or "Conflict Resolution" in your response ‚Äî those are internal steps only
- The response section should sound like a thoughtful person answering, not a system producing output
- Match response length to input complexity ‚Äî avoid padding simple answers with unnecessary depth"""
        
        response = self._query_llm(system_prompt, user_input)
        return {"final_response": response}

