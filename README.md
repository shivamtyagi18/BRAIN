<div align="center">

# ğŸ§  Brain System

### A Multi-Agent Cognitive Architecture Powered by LangGraph

*Five specialized AI agents â€” modeled after the human brain â€” collaborate to process your input and generate thoughtful, nuanced responses.*

[![Python 3.11+](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![LangGraph](https://img.shields.io/badge/Built%20with-LangGraph-orange.svg)](https://github.com/langchain-ai/langgraph)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

</div>

---

## ğŸ§© How It Works

Brain System maps biological brain functions to specialized AI agents that process every input in parallel â€” just like the human brain:

```mermaid
graph LR
    A[User Input] --> B[ğŸ”µ Sensory Agent<br>Thalamus]
    B --> C[ğŸŸ£ Memory Agent<br>Hippocampus]
    B --> D[ğŸŸ¢ Logic Agent<br>Frontal Lobe]
    B --> E[ğŸ”´ Emotional Agent<br>Amygdala]
    C --> F[ğŸŸ¡ Executive Agent<br>Prefrontal Cortex]
    D --> F
    E --> F
    F --> G[Final Response]
```

| Agent | Brain Analog | What It Does |
|:------|:-------------|:-------------|
| **Sensory** | Thalamus & Sensory Cortex | Parses and classifies raw input |
| **Memory** | Hippocampus | Retrieves relevant past interactions (short & long-term) |
| **Logic** | Left Frontal Lobe | Factual reasoning and analysis |
| **Emotional** | Amygdala & Limbic System | Sentiment, ethics, and emotional context |
| **Executive** | Prefrontal Cortex | Synthesizes all signals into a final decision |

## ğŸ­ Persona Mode

Upload a biography or autobiography, and the entire Brain responds **as that person would**.

The system extracts personality traits, speech patterns, reasoning style, and emotional tendencies â€” then injects tailored context into each agent. The Logic Agent thinks in their reasoning style, the Emotional Agent mirrors their emotional tendencies, and the Executive Agent speaks in their voice.

> **Example:** Upload Nelson Mandela's autobiography â†’ ask about dealing with conflict â†’ get a response reflecting his values of reconciliation, strategic patience, and ubuntu philosophy.

## ğŸš€ Quick Start

### 1. Clone & Install

```bash
git clone https://github.com/shivamtyagi18/BRAIN.git
cd BRAIN
pip install -r brain_system/requirements.txt
```

### 2. Configure (Optional)

Create a `.env` file in the project root for cloud providers:

```env
# Only needed if using Gemini or OpenAI
GOOGLE_API_KEY=your_key_here
OPENAI_API_KEY=your_key_here
```

> **No API key needed for Ollama** â€” runs entirely on your local machine.

### 3. Run

#### Web UI (Recommended)
```bash
python3.11 -m brain_system.app
```
Open **http://localhost:5001** in your browser.

#### Command Line
```bash
python3.11 -m brain_system.main
```

## ğŸ–¥ï¸ Web Interface

The web UI features:
- **Provider selection** â€” choose Gemini, OpenAI, or Ollama at startup
- **Persona upload** â€” drag & drop a `.txt` or `.pdf` biography
- **Live chat** â€” dark-mode interface with agent activity indicators
- **Mid-conversation persona switching** â€” change or clear persona without restarting

## ğŸ¤– Supported LLM Providers

| Provider | Requirements | Best For |
|:---------|:-------------|:---------|
| **Ollama** | [Ollama](https://ollama.ai) installed locally | Privacy, offline use, no cost |
| **Gemini** | `GOOGLE_API_KEY` in `.env` | High-quality responses |
| **OpenAI** | `OPENAI_API_KEY` in `.env` | GPT-4 class models |

### Using Ollama (Local)

```bash
# Install Ollama, then pull a model:
ollama pull mistral

# For uncensored output, try:
ollama pull dolphin-mistral
```

## ğŸ“ Project Structure

```
brain-system/
â”œâ”€â”€ run.sh                          # Single-command launcher
â””â”€â”€ brain_system/
    â”œâ”€â”€ app.py                      # Flask web server (API + UI)
    â”œâ”€â”€ main.py                     # CLI entry point
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ agents/
    â”‚   â”œâ”€â”€ base_agent.py           # Abstract base with persona injection
    â”‚   â”œâ”€â”€ sensory_agent.py        # Input parsing (Thalamus)
    â”‚   â”œâ”€â”€ memory_agent.py         # Context retrieval (Hippocampus)
    â”‚   â”œâ”€â”€ emotional_agent.py      # Sentiment analysis (Amygdala)
    â”‚   â”œâ”€â”€ logic_agent.py          # Reasoning (Frontal Lobe)
    â”‚   â””â”€â”€ executive_agent.py      # Decision synthesis (PFC)
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ orchestrator.py         # LangGraph workflow engine
    â”‚   â”œâ”€â”€ llm_interface.py        # Multi-provider LLM factory
    â”‚   â”œâ”€â”€ memory_store.py         # Persistent memory (JSON)
    â”‚   â”œâ”€â”€ document_loader.py      # TXT/PDF document ingestion
    â”‚   â””â”€â”€ persona.py              # Persona extraction & injection
    â””â”€â”€ web/
        â”œâ”€â”€ templates/index.html    # Chat interface
        â””â”€â”€ static/
            â”œâ”€â”€ css/style.css       # Dark-mode theme
            â””â”€â”€ js/app.js           # Frontend logic
```

## ğŸ”§ Architecture Highlights

- **LangGraph Orchestration** â€” Agents run as nodes in a compiled state graph with parallel execution for Memory, Logic, and Emotional processing
- **Modular LLM Factory** â€” Swap providers with a single parameter; no code changes needed
- **Dual Memory** â€” Short-term (conversation context) + Long-term (persistent JSON store with keyword retrieval)
- **Persona Injection** â€” Role-specific context: each agent gets *different* aspects of the persona profile tailored to its function

## ğŸ¤ Contributing

Contributions are welcome! Some ideas:

- **Vector memory** â€” Replace JSON keyword search with embedding-based retrieval
- **Additional agents** â€” Add a Creativity Agent, Social Agent, or Moral Reasoning Agent
- **Streaming responses** â€” Real-time token streaming in the web UI
- **Multi-turn persona** â€” Let the persona evolve based on the conversation
- **Agent transparency** â€” Show individual agent outputs before the final synthesis

## ğŸ“ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

<div align="center">
<i>Built with ğŸ§  by mapping neuroscience to multi-agent AI</i>
</div>
