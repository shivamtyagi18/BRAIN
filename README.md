<div align="center">

# ğŸ§  Brain System

### A Multi-Agent Cognitive Architecture Powered by LangGraph

*Five specialized AI agents â€” modeled after the human brain â€” collaborate to process your input and generate thoughtful, nuanced responses.*

[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyPI](https://img.shields.io/pypi/v/brain-system.svg)](https://pypi.org/project/brain-system/)
[![LangGraph](https://img.shields.io/badge/Built%20with-LangGraph-orange.svg)](https://github.com/langchain-ai/langgraph)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

</div>

---

## ğŸ§© How It Works

Brain System maps biological brain functions to specialized AI agents that process every input in parallel â€” just like the human brain:

```mermaid
graph LR
    A[User Input] --> B[ğŸ”µ Sensory Agent<br>Thalamus]
    B --> C[ğŸŸ£ Memory Agent<br>Hippocampus]
    B --> D[ğŸŸ¢ Logic Agent<br>Frontal Lobe]
    B --> E[ğŸ”´ Emotional Agent<br>Amygdala]
    C --> F[ğŸŸ¡ Executive Agent<br>Prefrontal Cortex]
    D --> F
    E --> F
    F --> G[Final Response]
```

| Agent | Brain Analog | What It Does |
|:------|:-------------|:-------------|
| **Sensory** | Thalamus & Sensory Cortex | Multi-layer signal classification, pattern recognition, salience detection |
| **Memory** | Hippocampus & DLPFC | LLM-driven contextual synthesis, associative linking, temporal weighting |
| **Logic** | Left Frontal Lobe & DLPFC | Deductive/inductive reasoning, fallacy detection, counter-arguments |
| **Emotional** | Amygdala, Insula & Cingulate | Emotional profiling, empathy reading, ethical safety checks |
| **Executive** | Full Prefrontal Cortex | Conflict resolution between agents, response calibration, integrated output |

## ğŸ­ Persona Mode

Upload a biography or autobiography, and the entire Brain responds **as that person would**.

The system extracts personality traits, speech patterns, reasoning style, and emotional tendencies â€” then injects tailored context into each agent. The Logic Agent thinks in their reasoning style, the Emotional Agent mirrors their emotional tendencies, and the Executive Agent speaks in their voice.

> **Example:** Upload Nelson Mandela's autobiography â†’ ask about dealing with conflict â†’ get a response reflecting his values of reconciliation, strategic patience, and ubuntu philosophy.

## ğŸ“¦ Install

```bash
pip install brain-system
```

> For the web UI, install the optional extra: `pip install brain-system[web]`

## ğŸš€ Quick Start â€” Library Usage

```python
from brain_system import BrainWrapper

# Create a Brain (choose provider: "gemini", "openai", or "ollama")
brain = BrainWrapper(provider="ollama", model_name="mistral")

# Process input through all 5 agents
result = brain.think("What is the meaning of justice?")

# Get the final synthesized response
print(result.response)

# Inspect individual agent signals
print(result.sensory)     # Thalamus â€” input classification
print(result.memory)      # Hippocampus â€” memory context
print(result.logic)       # Frontal Lobe â€” logical analysis
print(result.emotional)   # Amygdala â€” emotional analysis
```

### Persona Mode

Upload a biography/autobiography (`.txt` or `.pdf`) and the Brain responds as that person. Pass a **relative path** (resolved from your working directory) or an **absolute path**:

```python
# Relative path â€” looks in the directory where you run your script
brain.load_persona("gandhi_autobiography.pdf")

# Absolute path â€” works from anywhere
brain.load_persona("/Users/you/documents/gandhi_autobiography.pdf")

result = brain.think("How should we deal with injustice?")
print(result.response)    # Responds in Gandhi's voice

brain.clear_persona()     # Revert to default
```

### Memory Management

```python
# Custom memory file location
brain = BrainWrapper(provider="gemini", memory_path="./my_memory.json")

# Clear all stored memories
brain.clear_memory()
```

### API Reference

| Class / Method | Description |
|:---|:---|
| `BrainWrapper(provider, model_name, memory_path)` | Create a Brain instance |
| `.think(input) â†’ BrainResult` | Process input through the 5-agent pipeline |
| `.load_persona(filepath)` | Load a persona from `.txt` or `.pdf` |
| `.clear_persona()` | Remove the active persona |
| `.clear_memory()` | Erase all long-term memories |
| `.persona_active` | `bool` â€” is a persona loaded? |
| `.persona_name` | Name of the active persona |
| `BrainResult.response` | Final synthesized response |
| `BrainResult.agent_signals` | `dict` of each agent's raw output |
| `BrainResult.sensory / .memory / .logic / .emotional` | Shortcut accessors |

See [`examples/`](examples/) for complete usage scripts.

---

## ğŸ–¥ï¸ Development Setup

### Clone & Install

```bash
git clone https://github.com/shivamtyagi18/BRAIN.git
cd BRAIN
pip install -e ".[web,dev]"
```

### Configure (Optional)

Create a `.env` file in the project root for cloud providers:

```env
# Only needed if using Gemini or OpenAI
GOOGLE_API_KEY=your_key_here
OPENAI_API_KEY=your_key_here
```

> **No API key needed for Ollama** â€” runs entirely on your local machine.

### Run

#### Web UI
```bash
python -m brain_system.app
```
Open **http://localhost:5001** in your browser.

#### Command Line
```bash
brain-cli
```

## ğŸ–¥ï¸ Web Interface

The web UI features:
- **Provider selection** â€” choose Gemini, OpenAI, or Ollama at startup
- **Persona upload** â€” drag & drop a `.txt` or `.pdf` biography
- **Live chat** â€” dark-mode interface with agent activity indicators
- **Agent transparency** â€” expand each agent's internal reasoning with "Show agent signals"
- **Mid-conversation persona switching** â€” change or clear persona without restarting
- **New Chat** â€” full reset button to start fresh
- **Clear Memory** â€” wipe stored memories without restarting

## ğŸ¤– Supported LLM Providers

| Provider | Requirements | Best For |
|:---------|:-------------|:---------|
| **Ollama** | [Ollama](https://ollama.ai) installed locally | Privacy, offline use, no cost |
| **Gemini** | `GOOGLE_API_KEY` in `.env` | High-quality responses |
| **OpenAI** | `OPENAI_API_KEY` in `.env` | GPT-4 class models |

### Using Ollama (Local)

```bash
# Install Ollama, then pull a model:
ollama pull mistral

# For uncensored output, try:
ollama pull dolphin-mistral
```

## ğŸ“ Project Structure

```
brain-system/
â”œâ”€â”€ pyproject.toml                  # Package config & dependencies
â”œâ”€â”€ run.sh                          # Single-command launcher
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic_usage.py              # Minimal library usage
â”‚   â”œâ”€â”€ persona_mode.py             # Persona loading example
â”‚   â””â”€â”€ custom_provider.py          # Provider switching example
â””â”€â”€ brain_system/
    â”œâ”€â”€ __init__.py                 # Public API exports
    â”œâ”€â”€ wrapper.py                  # BrainWrapper â€” developer entry point
    â”œâ”€â”€ app.py                      # Flask web server (optional)
    â”œâ”€â”€ main.py                     # CLI entry point
    â”œâ”€â”€ agents/
    â”‚   â”œâ”€â”€ base_agent.py           # Abstract base with persona injection
    â”‚   â”œâ”€â”€ sensory_agent.py        # Input parsing (Thalamus)
    â”‚   â”œâ”€â”€ memory_agent.py         # Context retrieval (Hippocampus)
    â”‚   â”œâ”€â”€ emotional_agent.py      # Sentiment analysis (Amygdala)
    â”‚   â”œâ”€â”€ logic_agent.py          # Reasoning (Frontal Lobe)
    â”‚   â””â”€â”€ executive_agent.py      # Decision synthesis (PFC)
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ orchestrator.py         # LangGraph workflow engine
    â”‚   â”œâ”€â”€ llm_interface.py        # Multi-provider LLM factory
    â”‚   â”œâ”€â”€ memory_store.py         # Persistent memory (JSON)
    â”‚   â”œâ”€â”€ document_loader.py      # TXT/PDF document ingestion
    â”‚   â””â”€â”€ persona.py              # Persona extraction & injection
    â””â”€â”€ web/
        â”œâ”€â”€ templates/index.html    # Chat interface
        â””â”€â”€ static/
            â”œâ”€â”€ css/style.css       # Dark-mode theme
            â””â”€â”€ js/app.js           # Frontend logic
```

## ğŸ”§ Architecture Highlights

- **LangGraph Orchestration** â€” Agents run as nodes in a compiled state graph with parallel execution for Memory, Logic, and Emotional processing
- **Modular LLM Factory** â€” Swap providers with a single parameter; no code changes needed
- **Dual Memory** â€” Short-term (conversation context) + Long-term (persistent JSON store with keyword retrieval)
- **Persona Injection** â€” Role-specific context: each agent gets *different* aspects of the persona profile tailored to its function

## ğŸ¤ Contributing

Contributions are welcome! Some ideas:

- **Vector memory** â€” Replace JSON keyword search with embedding-based retrieval
- **Additional agents** â€” Add a Creativity Agent, Social Agent, or Moral Reasoning Agent
- **Streaming responses** â€” Real-time token streaming in the web UI
- **Multi-turn persona** â€” Let the persona evolve based on the conversation
- **Voice interface** â€” Add speech-to-text input and text-to-speech output

## ğŸ“ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

<div align="center">
<i>Built with ğŸ§  by mapping neuroscience to multi-agent AI</i>
</div>
